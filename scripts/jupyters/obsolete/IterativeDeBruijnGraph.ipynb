{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lrd_parser'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2d200939c5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlrd_parser\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLRD_Report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhamming_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentity_shift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOverlapAlignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress_homopolymer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mos_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msmart_makedirs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'lrd_parser'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "import edlib\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import operator\n",
    "from string import ascii_uppercase\n",
    "from itertools import groupby\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from lrd_parser import LRD_Report\n",
    "from utils.bio import hamming_distance, identity_shift, OverlapAlignment, compress_homopolymer\n",
    "from utils.os_utils import smart_makedirs\n",
    "import networkx as nx\n",
    "from debruijn_graph import DeBruijnGraph, iterative_graph, get_frequent_kmers, get_all_kmers\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from ndex2.nice_cx_network import NiceCXNetwork\n",
    "import ndex2.client as nc\n",
    "import ndex2\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and correct gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngaps(strings):\n",
    "    ngaps = 0\n",
    "    for r_id, string in strings.items():\n",
    "        r_ngaps = Counter(string)['=']\n",
    "        if r_ngaps >= 5:\n",
    "            mstring = string.lower()\n",
    "            mstring = mstring.replace('=', '|')\n",
    "            # print(r_id)\n",
    "            # print(mstring)\n",
    "            # print(\"\")\n",
    "        ngaps += r_ngaps\n",
    "    return ngaps\n",
    "\n",
    "def simple_stats(monomer_strings):\n",
    "    monomer_string_lens = [len(monomer_string) for monomer_string in monomer_strings.values()]\n",
    "    print(f'Len: Mean = {np.mean(monomer_string_lens)}, ' +\n",
    "          f'Min = {np.min(monomer_string_lens)}, ' +\n",
    "          f'Max = {np.max(monomer_string_lens)}, ' +\n",
    "          f'Total = {np.sum(monomer_string_lens)}')\n",
    "    ngaps = get_ngaps(monomer_strings)\n",
    "    print(f'#gaps = {ngaps}, %gaps = {ngaps / np.sum(monomer_string_lens)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd_report_fn = '/Poppy/abzikadze/centroFlye/centroFlye_repo/experiments/20191023/lrd_d6z1_rel3_Karen/decomposition.tsv'\n",
    "monomers_fn = '/Poppy/abzikadze/tandem_flye/data/human/isolated_centromeres/extracted_HORs/CEN6/monomers/inferred_monomers_single.fa'\n",
    "\n",
    "\n",
    "lrd_report = LRD_Report(lrd_report_fn=lrd_report_fn, monomers_fn=monomers_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings = {r_id: record.string for r_id, record in lrd_report.records.items()}\n",
    "len(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_stats(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_strings(monomer_strings, max_gap=0.05, max_lowercase=0.01):\n",
    "    filtered_strings = {}\n",
    "    for r_id, string in monomer_strings.items():\n",
    "        ngaps = Counter(string)['=']\n",
    "        lowercase = [s.islower() for s in string]\n",
    "        if np.mean(lowercase) > max_lowercase:\n",
    "            continue\n",
    "        if ngaps / len(string) <= max_gap:\n",
    "            filtered_strings[r_id] = string\n",
    "    return filtered_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings = filter_strings(monomer_strings)\n",
    "len(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_stats(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ma(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
    "\n",
    "def trim_read(monomer_string, max_gap, ma_window):\n",
    "    is_gap = [c == '=' for c in monomer_string]\n",
    "    ma = get_ma(is_gap, N=ma_window)\n",
    "    l = 0\n",
    "    while l < len(ma) and ma[l] > max_gap:\n",
    "        l += 1\n",
    "    r = len(ma) - 1\n",
    "    while r >= 0 and ma[r] > max_gap:\n",
    "        r -= 1\n",
    "    trimmed_read = monomer_string[l:r+1+ma_window]\n",
    "    trimmed_read = trimmed_read.strip('=')\n",
    "    trimmed_length = l + len(ma)-(r+1+ma_window)\n",
    "    return trimmed_read, trimmed_length\n",
    "\n",
    "def trim_reads(monomer_strings, max_gap=0.2, ma_window=30):\n",
    "    trimmed_reads = {}\n",
    "    for r_id, monomer_string in monomer_strings.items():\n",
    "        trimmed_read, trimmed_length = \\\n",
    "            trim_read(monomer_string, max_gap=max_gap, ma_window=ma_window)\n",
    "        trimmed_reads[r_id] = trimmed_read\n",
    "    return trimmed_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings = trim_reads(monomer_strings)\n",
    "len(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_stats(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_kmers, frequent_kmers_read_pos = get_frequent_kmers(monomer_strings, k=3, min_mult=1000)\n",
    "db = DeBruijnGraph(k=3)\n",
    "db.add_kmers(frequent_kmers, coverage=frequent_kmers)\n",
    "\n",
    "#hors, _ = db.get_contigs()\n",
    "print(db.get_contigs())\n",
    "nx.drawing.nx_pydot.write_dot(db.graph, 'db.dot')\n",
    "\n",
    "\n",
    "def correct_gaps(monomer_strings, hors, max_gap=0.3, nhor=5):\n",
    "    corrected_strings = {}\n",
    "    for r_id, monomer_string in monomer_strings.items():\n",
    "            corrected_string = list(monomer_string)\n",
    "            for single_hor in hors:\n",
    "                for i_nhor in range(1, nhor+1):\n",
    "                    hor = single_hor * i_nhor\n",
    "                    hor_len = len(hor)\n",
    "                    for i in range(len(monomer_string)-hor_len+1):\n",
    "                        kmer = monomer_string[i:i+hor_len]\n",
    "                        gap_cnt = Counter(kmer)['=']\n",
    "                        if gap_cnt == 0 or gap_cnt / hor_len > max_gap:\n",
    "                            continue\n",
    "                        hd, _ = hamming_distance(kmer, hor, match_char=set('='))\n",
    "                        if hd == 0:\n",
    "                            # print(hor)\n",
    "                            # print(kmer)\n",
    "                            # print(\"\")\n",
    "                            corrected_string[i:i+hor_len] = list(hor)\n",
    "                        \n",
    "            corrected_strings[r_id] = ''.join(corrected_string)\n",
    "    return corrected_strings\n",
    "\n",
    "# monomer_strings = correct_gaps(monomer_strings, hors)\n",
    "# ngaps = get_ngaps(monomer_strings)\n",
    "# print(ngaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_stats(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_read_coverage(frequent_kmers_read_pos, monomer_strings, k):\n",
    "    coverage = {}\n",
    "    for r_id, string in monomer_strings.items():\n",
    "        coverage[r_id] = [0] * (len(string) + 1)\n",
    "    for pairs in frequent_kmers_read_pos.values():\n",
    "        for r_id, pos in pairs:\n",
    "            coverage[r_id][pos] += 1\n",
    "            coverage[r_id][pos+k] -= 1\n",
    "    for r_id in coverage:\n",
    "        coverage[r_id] = np.cumsum(coverage[r_id])\n",
    "        coverage[r_id] = coverage[r_id][:-1]\n",
    "    return coverage\n",
    "\n",
    "def find_zero_cov(coverage):\n",
    "    all_zero_cov = {}\n",
    "    for r_id in coverage:\n",
    "        zero_cov_flatten = np.where(coverage[r_id] == 0)[0]\n",
    "        if len(zero_cov_flatten) == 0:\n",
    "            all_zero_cov[r_id] = []\n",
    "            continue\n",
    "        zero_cov = []\n",
    "        zero_cov.append([zero_cov_flatten[0]])\n",
    "        for pos in zero_cov_flatten[1:]:\n",
    "            if pos == zero_cov[-1][-1] + 1:\n",
    "                zero_cov[-1].append(pos)\n",
    "            else:\n",
    "                zero_cov.append([pos])\n",
    "        \n",
    "        all_zero_cov[r_id] = [(x[0], x[-1]) for x in zero_cov]\n",
    "        \n",
    "    return all_zero_cov\n",
    "\n",
    "def find_path_debr(zero_cov, read_seq, r_id, k, db,\n",
    "                   max_len=1000, min_len=1, min_overlap=3, max_overlap=30, max_dist=1):\n",
    "    k -= 1\n",
    "    results = {}\n",
    "    corrected_seq = list(read_seq)\n",
    "    for st, en in zero_cov[::-1]:\n",
    "        if st < k or en > len(read_seq) - 1 - k or en-st+1 > max_len or en-st+1 < min_len:\n",
    "            # results[(st, en)] = '-'\n",
    "            continue\n",
    "        # print(r_id, st, en)\n",
    "        st_kmer, en_kmer = read_seq[st-k:st], read_seq[en+1:en+1+k]\n",
    "        # assert st_kmer in frequent_kmers\n",
    "        # assert en_kmer in frequent_kmers\n",
    "        # assert read_seq[st-k+1:st+1] not in frequent_kmers\n",
    "        # assert read_seq[en:en+k] not in frequent_kmers\n",
    "        # assert st_kmer in db.graph.nodes\n",
    "\n",
    "        u = st_kmer\n",
    "        kmers = [u]\n",
    "        while u != en_kmer and len(kmers) < 2*k:\n",
    "            u_node = db.node_mapping[u]\n",
    "            out_edges = list(db.graph.out_edges(u_node))\n",
    "            # print(list(db.graph.nodes(data=True))[0])\n",
    "            # print(u, len(db.graph.in_edges(u_node)), len(out_edges))\n",
    "            # print(out_edges)\n",
    "            if len(out_edges) == 1:\n",
    "                edge = out_edges[0]\n",
    "                assert edge[0] == u_node\n",
    "                u_node = edge[1]\n",
    "                u = db.rev_node_mapping[u_node]\n",
    "                kmers.append(u)\n",
    "            else:\n",
    "                break\n",
    "            \n",
    "        if len(kmers) < min_overlap + 1:\n",
    "            # results[(st, en)] = '-'\n",
    "            # print(kmers)\n",
    "            continue\n",
    "\n",
    "        # print(len(kmers))\n",
    "        extension = [kmer[-1] for kmer in kmers[1:]]\n",
    "        extension = ''.join(extension)\n",
    "        read_segment = read_seq[en+1:en+len(extension)]\n",
    "        # print(extension)\n",
    "        # print(read_segment)\n",
    "        \n",
    "        ident = identity_shift(extension[:max_overlap],\n",
    "                               read_segment[:max_overlap],\n",
    "                               min_overlap=min_overlap,\n",
    "                               match_char=set('='))\n",
    "        # print(ident)\n",
    "        if ident['id'] == 1 and ident['shift'] is not None:\n",
    "            # print(ident)\n",
    "            correction = extension[:ident['shift']]\n",
    "            if abs(len(correction) - (en-st+1)) > 10:\n",
    "                # results[(st, en)] = '-'\n",
    "                continue\n",
    "            print(read_seq[st:en+1], read_seq[st-5:en+6])\n",
    "            print(correction, len(correction))\n",
    "            print(\"\")\n",
    "            results[(st, en)] = (read_seq[st:en+1], correction)\n",
    "            corrected_seq[st:en+1] = list(correction)\n",
    "    corrected_seq = ''.join(corrected_seq)\n",
    "    return results, corrected_seq\n",
    "\n",
    "\n",
    "def correct_seq(monomer_strings, k, min_mult=10):\n",
    "    frequent_kmers, frequent_kmers_read_pos = get_frequent_kmers(monomer_strings, k=k, min_mult=min_mult)\n",
    "    db = DeBruijnGraph(k=k)\n",
    "    db.add_kmers(frequent_kmers, coverage=frequent_kmers)\n",
    "    coverage = get_read_coverage(frequent_kmers_read_pos=frequent_kmers_read_pos,\n",
    "                                 monomer_strings=monomer_strings,\n",
    "                                 k=k)\n",
    "    zero_cov = find_zero_cov(coverage=coverage)\n",
    "    \n",
    "    all_corrections = {}\n",
    "    corrected_seqs = {}\n",
    "    for r_id in zero_cov:\n",
    "        all_corrections[r_id], corrected_seqs[r_id] = find_path_debr(zero_cov[r_id],\n",
    "                                                              monomer_strings[r_id],\n",
    "                                                              r_id=r_id,\n",
    "                                                              k=k,\n",
    "                                                              db=db)\n",
    "    return all_corrections, corrected_seqs\n",
    "\n",
    "\n",
    "def correct_reads(monomer_strings, min_k=10, max_k=200, niter=1):\n",
    "    corrected_seqs = monomer_strings\n",
    "    for k in range(min_k, max_k):\n",
    "        for i in range(niter):\n",
    "            print(k, i)\n",
    "            all_corrections, corrected_seqs = correct_seq(corrected_seqs, k=k)\n",
    "            for r_id, corrections in all_corrections.items():\n",
    "                if len(corrections):\n",
    "                    print(r_id, corrections)\n",
    "    return corrected_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# monomer_strings = correct_reads(monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngaps = get_ngaps(monomer_strings)\n",
    "# print(ngaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_k, max_k = 10, 400\n",
    "contigs, dbs, all_frequent_kmers, all_frequent_kmers_read_pos = \\\n",
    "    iterative_graph(monomer_strings, min_k=min_k, max_k=max_k,\n",
    "                    outdir='/Poppy/abzikadze/centroFlye/centroFlye_repo/experiments/20191115/db_wi_error_corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After error correction i could get to max_k = 634\n",
    "# min_k, max_k = 10, 634\n",
    "# contigs, dbs = iterative_graph(monomer_strings, min_k=min_k, max_k=max_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = dbs[max(dbs.keys())]\n",
    "# db = dbs[634]\n",
    "# db = dbs2[500]\n",
    "# db = dbs[650]\n",
    "\n",
    "\n",
    "# assert nx.number_weakly_connected_components(db.graph) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping of reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(contigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contig_lens = sorted(len(contig) for contig in contigs)\n",
    "print(contig_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges, coverage = db.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_lens = sorted(len(edge) for edge in edges)\n",
    "print(edge_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.drawing.nx_pydot.write_dot(db.graph, 'db.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nice_cx_debr_graph = ndex2.create_nice_cx_from_networkx(db.graph)\n",
    "\n",
    "#nice_cx_debr_graph.upload_to(server='public.ndexbio.org', username = 'seryrzu',\n",
    "#                             password = 'Kxoq)V?Z]vrgt87x*XO,:we)U&RwEEG!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reads(monomer_strings, db, db_index=None):\n",
    "    if db_index is None:\n",
    "        db_index = db.index_edges()\n",
    "    mapping = {}\n",
    "    db_edges = list(db.graph.edges(keys=True))\n",
    "    for r_id, string in monomer_strings.items():\n",
    "        split_strings = list(filter(lambda string: len(string), string.split('=')))\n",
    "        split_lens = [0] + [len(split_string) for split_string in split_strings]\n",
    "        cum_split_lens = np.cumsum(split_lens)\n",
    "        read_coords = []\n",
    "        for split_ind, split_string in enumerate(split_strings):\n",
    "            for i in range(len(split_string)-db.k+1):\n",
    "                kmer = split_string[i:i+db.k]\n",
    "                if kmer in db_index[len(kmer)]:\n",
    "                    read_coords.append(db_index[len(kmer)][kmer])\n",
    "        \n",
    "        path = [x[0] for x in read_coords]\n",
    "        path = [x[0] for x in groupby(path)]\n",
    "        path = [db_edges[edge_ind] for edge_ind in path]\n",
    "        \n",
    "        valid_path = True\n",
    "        for e1, e2 in zip(path[:-1], path[1:]):\n",
    "            if e1[1] != e2[0]:\n",
    "                valid_path = False\n",
    "                break\n",
    "        if len(read_coords):\n",
    "            mapping[r_id] = (read_coords[0], read_coords[-1], valid_path, path)\n",
    "        else:\n",
    "            mapping[r_id] = None\n",
    "    return mapping\n",
    "\n",
    "mappings = map_reads(monomer_strings, db)\n",
    "\n",
    "print(np.mean([read_mapping is not None for read_mapping in mappings.values()]))\n",
    "print(np.mean([read_mapping[2] for read_mapping in mappings.values() \\\n",
    "               if read_mapping is not None]))\n",
    "print(np.sum([read_mapping[2] for read_mapping in mappings.values() \\\n",
    "               if read_mapping is not None]))\n",
    "\n",
    "for r_id, read_mapping in mappings.items():\n",
    "    if read_mapping is not None and read_mapping[2]:\n",
    "        print(r_id, len(monomer_strings[r_id]), len(monomer_strings[r_id]) * 171,\n",
    "              len(db.get_path(read_mapping[-1])), read_mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_mappings(mappings, db):\n",
    "    filtered_mappings = {}\n",
    "    contigs, contig_paths = db.get_contigs()\n",
    "    for r_id, read_mapping in mappings.items():\n",
    "        if read_mapping is None or not read_mapping[-2]:\n",
    "            continue\n",
    "        read_mapping = read_mapping[-1]\n",
    "        rm_len = len(read_mapping)\n",
    "        if rm_len == 1:\n",
    "            continue\n",
    "        in_contig = False\n",
    "        for path in contig_paths:\n",
    "            path = list(path)\n",
    "            for i in range(len(path)-rm_len+1):\n",
    "                subpath = path[i:i+rm_len]\n",
    "                # print(subpath)\n",
    "                # print(read_mapping)\n",
    "                if subpath == read_mapping:\n",
    "                    in_contig = True\n",
    "                    break\n",
    "            if in_contig:\n",
    "                break\n",
    "        if not in_contig:\n",
    "            filtered_mappings[r_id] = read_mapping\n",
    "            # print(r_id, read_mapping)\n",
    "        else:\n",
    "            pass\n",
    "            # print(r_id, read_mapping)\n",
    "    return filtered_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaffolding_reads = filter_mappings(mappings, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scaffolding_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scaffold_links(scaffolding_reads, db):\n",
    "    scaffolds = defaultdict(list)\n",
    "    contigs, contig_paths = db.get_contigs()\n",
    "    for r_id, scaffolding_read in scaffolding_reads.items():\n",
    "        best_lo, best_lo_len, best_lo_shift = None, 0, 0\n",
    "        best_ro, best_ro_len, best_ro_shift = None, 0, 0\n",
    "        \n",
    "        for i, path in enumerate(contig_paths):\n",
    "            l_overlap = identity_shift(path, scaffolding_read, min_overlap=1)\n",
    "            r_overlap = identity_shift(scaffolding_read, path, min_overlap=1)\n",
    "            if l_overlap['id'] == 1 and len(l_overlap['alt_shifts']) == 0 \\\n",
    "                    and l_overlap['len'] >= best_lo_len \\\n",
    "                    and l_overlap['shift'] + len(scaffolding_read) > len(path) \\\n",
    "                    and l_overlap['shift'] >= 1:\n",
    "                best_lo = list(path)\n",
    "                best_lo_len = l_overlap['len']\n",
    "                best_lo_shift = l_overlap['shift']\n",
    "            \n",
    "            if r_overlap['id'] == 1 and len(r_overlap['alt_shifts']) == 0 \\\n",
    "                    and r_overlap['len'] >= best_ro_len \\\n",
    "                    and r_overlap['shift'] + len(path) > len(scaffolding_read) \\\n",
    "                    and r_overlap['shift'] >= 1:\n",
    "                best_ro = list(path)\n",
    "                best_ro_len = r_overlap['len']\n",
    "                best_ro_shift = r_overlap['shift']\n",
    "            \n",
    "        if best_lo is not None and best_ro is not None:\n",
    "            scaffold = best_lo[:best_lo_shift] + scaffolding_read[:best_ro_shift] + best_ro\n",
    "            scaffold = tuple(scaffold)\n",
    "            scaffolds[scaffold].append(r_id)\n",
    "#             print('left')\n",
    "#             print(r_id)\n",
    "#             print('read', scaffolding_read)\n",
    "#             print('contig', best_lo)\n",
    "#             print(\"\")\n",
    "#             print('right')\n",
    "#             print(r_id)\n",
    "#             print('read', scaffolding_read)\n",
    "#             print('contig', best_ro)\n",
    "#             print(\"\")\n",
    "#             print(\"scaffold:\", scaffold)\n",
    "#             print(len(db.get_path(scaffold)))\n",
    "#             print(\"\")\n",
    "    \n",
    "    return scaffolds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffolds = get_scaffold_links(scaffolding_reads, db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for scaffold in scaffolds:\n",
    "    print(scaffold, len(db.get_path(scaffold)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual scaffolding of long edges in graph with k=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_uppercase\n",
    "\n",
    "man_assembly_fn = \"/Poppy/abzikadze/centroFlye/centroFlye_repo/data/D6Z1/CEN6_ManVERSION3.tsv\"\n",
    "\n",
    "units = []\n",
    "with open(man_assembly_fn) as f:\n",
    "    for line in f:\n",
    "        line = line.strip().split('\\t')\n",
    "        st, en = int(line[-2]), int(line[-1])\n",
    "        if en < 17:\n",
    "            en -= 1\n",
    "        units.append((st, en))\n",
    "\n",
    "from string import ascii_uppercase\n",
    "from itertools import groupby\n",
    "\n",
    "def monomers2units(s, unit_len=18):\n",
    "    units = []\n",
    "    i = 0\n",
    "    while i < len(s):\n",
    "        u_st = i\n",
    "        j = 0\n",
    "        shift = ascii_uppercase.find(s[i])\n",
    "        if shift == -1:\n",
    "            i += 1\n",
    "            units.append('=')\n",
    "            continue\n",
    "        while i + j < len(s) and ascii_uppercase[j+shift] == s[i+j]:\n",
    "            j += 1\n",
    "        if shift == 0 and j == unit_len:\n",
    "            units.append('Full')\n",
    "        else:\n",
    "            units.append((shift, shift+j-1))\n",
    "        i += j\n",
    "    compressed_units = []\n",
    "    for key, group in groupby(units):\n",
    "        compressed_units.append((key, len(list(group))))\n",
    "    return compressed_units\n",
    "        \n",
    "def units2monomers(units):\n",
    "    monomers = []\n",
    "    for (s, e) in units:\n",
    "        monomers.append(ascii_uppercase[s:e+1])\n",
    "    monomers = ''.join(monomers)\n",
    "    return monomers\n",
    "\n",
    "ref_monomers = units2monomers(units)\n",
    "\n",
    "def get_cov(ref_monomers, seqs, max_ed=10000):\n",
    "    coverage = [0] * (len(ref_monomers)+1)\n",
    "    for r_id, seq in seqs.items():\n",
    "        alignment = edlib.align(seq,\n",
    "                                ref_monomers,\n",
    "                                mode='HW',\n",
    "                                task='locations',\n",
    "                                k=max_ed)\n",
    "        print(r_id, alignment, np.diff(alignment['locations']))\n",
    "        loc = alignment['locations']\n",
    "        if loc is None or len(loc) != 1:\n",
    "            continue\n",
    "        else:\n",
    "            loc = loc[0]\n",
    "        coverage[loc[0]] += 1\n",
    "        coverage[loc[1]+1] -= 1\n",
    "    coverage = np.cumsum(coverage)\n",
    "    return coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = dbs[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_edges(db, min_len=1000, max_cov=30):\n",
    "    edges = {}\n",
    "    for edge in db.graph.edges(data=True, keys=True):\n",
    "        edge_len = len(edge[-1]['edge_kmer'])\n",
    "        edge_cov = np.median(edge[-1]['coverages'])\n",
    "        if edge_len >= min_len and edge_cov <= max_cov:\n",
    "            print(edge[:-1], edge_len, np.median(edge_cov))\n",
    "            edges[edge[:-1]] = edge[-1]['edge_kmer']\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "long_edges = get_long_edges(db)\n",
    "len(long_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cov = get_cov(ref_monomers, long_edges)\n",
    "plt.plot(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_reads = {k: v for k, v in monomer_strings.items() if len(v) >= 1000}\n",
    "len(long_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = get_cov(ref_monomers, long_reads)\n",
    "plt.plot(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_edges(edges, reads, min_overlap=300, min_id=0.97):\n",
    "    connections = defaultdict(list)\n",
    "    for r_id, read in reads.items():\n",
    "        b_pref_al, b_pref_overlap, b_pref_edge = None, 0, None\n",
    "        b_suf_al, b_suf_overlap, b_suf_edge = None, 0, None\n",
    "        \n",
    "        # print(\"\\n!!!!!\\n\")\n",
    "        for e_id, edge in edges.items():\n",
    "            er = identity_shift(edge, read, min_overlap, match_char=set('=?'))\n",
    "            re = identity_shift(read, edge, min_overlap, match_char=set('=?'))\n",
    "            if er['shift'] != None and len(er['alt_shifts']) == 0 and er['id'] > min_id \\\n",
    "                    and er['len'] > b_pref_overlap:\n",
    "                b_pref_al = er\n",
    "                b_pref_overlap = b_pref_overlap\n",
    "                b_pref_edge = e_id\n",
    "            \n",
    "            if re['shift'] != None and len(re['alt_shifts']) == 0 and re['id'] > min_id \\\n",
    "                    and re['len'] > b_suf_overlap:\n",
    "                b_suf_al = re\n",
    "                b_suf_overlap = b_suf_overlap\n",
    "                b_suf_edge = e_id\n",
    "        \n",
    "        if b_suf_edge is not None and b_pref_edge is not None:\n",
    "            print(r_id)\n",
    "            print(b_pref_edge, b_pref_al)\n",
    "            print(b_suf_edge, b_suf_al)\n",
    "            dist = len(read) - b_pref_al['len'] - b_suf_al['len']\n",
    "            print(dist)\n",
    "            connections[(b_pref_edge, b_suf_edge)].append(\n",
    "                (r_id, b_pref_al['len'], b_pref_al['id'], dist, b_suf_al['len'], b_suf_al['id'])\n",
    "            )\n",
    "    return connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connections = connect_edges(long_edges, monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cov = get_cov(ref_monomers, long_edges)\n",
    "plt.plot(cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge_pair, read_list in connections.items():\n",
    "    dist_cnt = Counter(x[3] for x in read_list)\n",
    "    mc = dist_cnt.most_common(1)\n",
    "    if mc[0][1] >= 2:\n",
    "        print(edge_pair)\n",
    "        for r_id, pref_ov_len, pref_ov_id, dist, suf_ov_len, suf_ov_id in read_list:\n",
    "            print(f'{r_id} {pref_ov_len:4} {pref_ov_id:5.2}, {dist:4}, {suf_ov_len:4}, {suf_ov_id:5.2}')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_reads(monomer_strings, db, db_index=None):\n",
    "    if db_index is None:\n",
    "        db_index = db.index_edges()\n",
    "    mapping = {}\n",
    "    db_edges = list(db.graph.edges(keys=True))\n",
    "    for r_id, string in monomer_strings.items():\n",
    "        split_strings = list(filter(lambda string: len(string), string.split('=')))\n",
    "        split_lens = [0] + [len(split_string) for split_string in split_strings]\n",
    "        cum_split_lens = np.cumsum(split_lens)\n",
    "        read_coords = []\n",
    "        for split_ind, split_string in enumerate(split_strings):\n",
    "            for i in range(len(split_string)-db.k+1):\n",
    "                kmer = split_string[i:i+db.k]\n",
    "                if kmer in db_index[len(kmer)]:\n",
    "                    read_coords.append(db_index[len(kmer)][kmer])\n",
    "        \n",
    "        path = [x[0] for x in read_coords]\n",
    "        path = [x[0] for x in groupby(path)]\n",
    "        path = [db_edges[edge_ind] for edge_ind in path]\n",
    "        \n",
    "        valid_path = True\n",
    "        for e1, e2 in zip(path[:-1], path[1:]):\n",
    "            if e1[1] != e2[0]:\n",
    "                valid_path = False\n",
    "                break\n",
    "        if len(read_coords):\n",
    "            mapping[r_id] = (read_coords[0], read_coords[-1], valid_path, path)\n",
    "        else:\n",
    "            mapping[r_id] = None\n",
    "    return mapping\n",
    "\n",
    "mappings = map_reads(monomer_strings, db)\n",
    "\n",
    "print(np.mean([read_mapping is not None for read_mapping in mappings.values()]))\n",
    "print(np.mean([read_mapping[2] for read_mapping in mappings.values() \\\n",
    "               if read_mapping is not None]))\n",
    "print(np.sum([read_mapping[2] for read_mapping in mappings.values() \\\n",
    "               if read_mapping is not None]))\n",
    "\n",
    "for r_id, read_mapping in mappings.items():\n",
    "    if read_mapping is not None and read_mapping[2]:\n",
    "        print(r_id, len(monomer_strings[r_id]), len(monomer_strings[r_id]) * 171,\n",
    "              len(db.get_path(read_mapping[-1])), read_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between A  = (7, 9915, 0) and B = (5120, 5451, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomers2units(long_edges[(7, 9915, 0)]) # A in unit form\n",
    "# monomers2units(long_edges[(5120, 5451, 0)]) # B in unit form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomers2units(db.graph.get_edge_data(9915, 7, 0)['edge_kmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomers2units(db.graph.get_edge_data(14132, 5491, 0)['edge_kmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomers2units(monomer_strings['ab79a298-1f1a-44da-a174-6a52ae8abfcd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomer_strings['0c50866b-f780-4551-a4bb-aa35a72f3f4d'][323:323+136]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomer_strings['1b4bd09e-07f3-4455-b041-c4599b6fbe3d'][901:901+138]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_paths_thru_complex_nodes(dbs[303], monomer_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# monomers2units(dbs[303].graph.get_edge_data(7, 8, 0)['edge_kmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monomers2units(dbs[303].graph.get_edge_data(8, 7, 0)['edge_kmer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings = map_reads({'ab79a298-1f1a-44da-a174-6a52ae8abfcd': monomer_strings['ab79a298-1f1a-44da-a174-6a52ae8abfcd']},\n",
    "#                     dbs[304])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[303].rev_node_mapping[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[303].rev_node_mapping[3199]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[303].rev_node_mapping[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[304].rev_node_mapping[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erroneous_kmer = dbs[304].graph.get_edge_data(6732, 7, 0)['edge_kmer']\n",
    "# len(erroneous_kmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt_erroneous_kmer = 0\n",
    "# for _ in monomer_strings.values():\n",
    "#     __ = Counter([_[i:i+len(erroneous_kmer)] for i in range(len(_)-len(erroneous_kmer)+1)])\n",
    "#     cnt_erroneous_kmer += __[erroneous_kmer]\n",
    "# print(cnt_erroneous_kmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[304].graph.get_edge_data(7, 13999, 0)['edge_kmer'][:303]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erroneous_kmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[303].graph.get_edge_data(8, 13964, 0)['edge_kmer'][:302]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbs[303].graph.get_edge_data(7, 8, 0)['edge_kmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_frequent_kmers_read_pos[304][dbs[304].graph.get_edge_data(6732, 7, 0)['edge_kmer']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for contig_path in dbs[303].get_contigs()[1]:\n",
    "#     if dbs[303].get_path(contig_path) == dbs[303].get_contigs()[0][21]:\n",
    "#        print(contig_path)\n",
    "#         print(dbs[303].get_path(contig_path))\n",
    "#         print(erroneous_kmer in dbs[303].get_path(contig_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dbs[303].rev_node_mapping[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between B = (5120, 5451, 0) and C  = (4445, 10624, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'map_reads' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-156fb7bdc265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m mappings = map_reads({'aff6bdf9-4388-46e6-9aa5-af5c6c88258d': monomer_strings['aff6bdf9-4388-46e6-9aa5-af5c6c88258d']},\n\u001b[0m\u001b[1;32m      2\u001b[0m                      dbs[400])\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'map_reads' is not defined"
     ]
    }
   ],
   "source": [
    "mappings = map_reads({'aff6bdf9-4388-46e6-9aa5-af5c6c88258d': monomer_strings['aff6bdf9-4388-46e6-9aa5-af5c6c88258d']},\n",
    "                     dbs[400])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_hor(units):\n",
    "    code_units = []\n",
    "    i = 0\n",
    "    while i < len(units) - 1:\n",
    "        u1, u2 = units[i], units[i+1]\n",
    "        if u1 == ((0, 1), 1) and u2 == ((5, 17), 1):\n",
    "            code_units.append('M')\n",
    "            i += 2\n",
    "        else:\n",
    "            code_units.append(u1)\n",
    "            i += 1\n",
    "    compressed_units = []\n",
    "    for key, group in groupby(code_units):\n",
    "        if len(list(group)) == 1:\n",
    "            compressed_units.append(key)\n",
    "        else:\n",
    "            compressed_units.append((key[0], len(list(group))))\n",
    "    return compressed_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(4445, 10624, 0)]) # C in unit form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = map_reads({'f3a7eb72-23c5-4c60-97d8-be9c7cb6285b': monomer_strings['f3a7eb72-23c5-4c60-97d8-be9c7cb6285b']},\n",
    "                     dbs[400])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between C  = (4445, 10624, 0) and D = (942, 7050, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings = map_reads(monomer_strings,\n",
    "                     dbs[400])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(942, 7050, 0)]) # D in unit form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['2d7e41d5-9657-4c4a-bafe-de2baf162d51']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['347cb721-6ad0-4df3-9bd2-4bc0a3c08c8d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['459cabbd-30ad-4a2a-985a-5983b49e50ff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['535aa52e-6acc-4f47-af7f-e728e2b8c0bc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbs[400].rev_node_mapping[13393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs[400].rev_node_mapping[11008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (c1, c2) in enumerate(zip(dbs[400].rev_node_mapping[13393], dbs[400].rev_node_mapping[11008])):\n",
    "    if c1 == c2 :\n",
    "        print(i, c1.lower(), c2.lower())\n",
    "    else:\n",
    "        print(i, c1, c2, '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frequent_kmers_read_pos[399][dbs[400].rev_node_mapping[11008]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_frequent_kmers_read_pos[399][dbs[400].rev_node_mapping[13393]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['9bf34c41-751f-4ef2-b150-b4e287b12eaa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['9c6be407-612e-4e37-becb-34e62c64c7e2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['b55aea96-cbe9-4c7b-9b0a-0501dd830ba8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['d2f81138-e67b-4063-bdeb-3a4f5f9c31e0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between D = (942, 7050, 0) and E  = (5120, 11585, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['86fdd7a8-71b5-46fa-90d2-5e6888ae2289']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_cov(mappings, db):\n",
    "    cov = {}\n",
    "    for edge in db.graph.edges(keys=True):\n",
    "         cov[edge] = 0\n",
    "    \n",
    "    for r_id, mapping in mappings.items():\n",
    "        if mapping is not None and mapping[-2]:\n",
    "            for edge in mapping[-1]:\n",
    "                cov[edge] += 1\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_cov = get_edge_cov(mappings=mappings, db=dbs[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_id, e_cov in edge_cov.items():\n",
    "    if e_cov == 0:\n",
    "        print(e_id, e_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_cov[(4554, 4728,0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (4445, 10624, 0) in mapping[-1]:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(5120, 11585, 0)]) # D in unit form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between E  = (5120, 11585, 0) and F = (2929, 1532, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dbs[400].graph.get_edge_data(11585, 2929, 0)['edge_kmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs[400].graph.get_edge_data(11585, 2929, 1)['edge_kmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (c1, c2) in enumerate(zip(dbs[400].graph.get_edge_data(11585, 2929, 0)['edge_kmer'],\n",
    "                                 dbs[400].graph.get_edge_data(11585, 2929, 1)['edge_kmer'])):\n",
    "    if c1 == c2 :\n",
    "        print(i, c1.lower(), c2.lower())\n",
    "    else:\n",
    "        print(i, c1, c2, '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(2929, 2239, 0)]) # F in unit form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between F = (2929, 1532, 0) and G  = (2466, 5451, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(2466, 5451, 0)]) # G in unit form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings['bee10b9a-2130-48fe-ae17-ab10d9f1f4bf'][:374] == \\\n",
    "db.graph.get_edge_data(2929, 2239, 0)['edge_kmer'][-374:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings['bee10b9a-2130-48fe-ae17-ab10d9f1f4bf'][:374] == \\\n",
    "db.graph.get_edge_data(3889, 2239, 0)['edge_kmer'][-374:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.graph.get_edge_data(2929, 2239, 0)['edge_kmer'][-374:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mappings['bee10b9a-2130-48fe-ae17-ab10d9f1f4bf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['a571367d-42ce-4bda-a218-0c38dc511dcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings['a571367d-42ce-4bda-a218-0c38dc511dcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd_report.records['b988001c-6155-4fa8-8300-2ec01c12eeb1'].string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['6ee658cf-a26e-4c5a-87e1-aaa6a554d8a9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['7bacbcf9-5c10-4e40-b09c-5b8c07ec0470']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (2929, 2239, 0) in mapping[-1] and len(mapping[-1]) > 1:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (2317, 5625, 0) in mapping[-1] and len(mapping[-1]) > 1:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (2415, 4554, 0) in mapping[-1] and len(mapping[-1]) > 1:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (4728, 3889, 0) in mapping[-1] and len(mapping[-1]) > 10:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (4728, 3889, 1) in mapping[-1] and len(mapping[-1]) > 1:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (2466, 4554, 0) in mapping[-1] and len(mapping[-1]) > 5:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (4728, 3889, 1) in mapping[-1]:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between G = (2466, 5451, 0) and H = (5509, 11189, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['0b1f944b-90f7-4e17-a1cd-f02d38d0f84c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection between H = (5509, 11189, 0) and * = (11189, 7050, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappings['e292a036-e0a2-458b-8ee2-8e61272844a3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r_id, mapping in mappings.items():\n",
    "    if mapping is not None and mapping[-2]:\n",
    "        if (11189, 7050, 0) in mapping[-1]:\n",
    "            print(r_id, mapping[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(11189, 7050, 0)]) # * in unit form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomers2units(long_edges[(5509, 11189, 0)]) # H in unit form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual scaffold guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gﬁfold_path += mappings['6ee658cf-a26e-4c5a-87e1-aaa6a554d8a9'][-1] # from E inside dublication\n",
    "    scaffold_path += [(2415, 4554, 0), (4554, 4728, 0), (4728, 3889, 1), (3889, 2239, 0)]\n",
    "    scaffold_path += mappings['bee10b9a-2130-48fe-ae17-ab10d9f1f4bf'][-1] # up to G\n",
    "    scaffold_path += mappings['0b1f944b-90f7-4e17-a1cd-f02d38d0f84c'][-1][1:] # up to H\n",
    "    scaffold_path += mappings['e292a036-e0a2-458b-8ee2-8e61272844a3'][-1][1:]\n",
    "    \n",
    "    scaffold = db.get_path(scaffold_path)\n",
    "    return scaffold, scaffold_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaffold, scaffold_path = get_scaffold_v1_Nov18(dbs[400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edlib.align(scaffold, ref_monomers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = get_cov(ref_monomers, monomer_strings)\n",
    "plt.plot(cov)\n",
    "plt.title('Coverage of Karen cen6 assembly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = get_cov(scaffold, monomer_strings)\n",
    "plt.plot(cov)\n",
    "plt.title('Coverage of our cen6 assembly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monomer_strings['ab79a298-1f1a-44da-a174-6a52ae8abfcd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd_report.records['ab79a298-1f1a-44da-a174-6a52ae8abfcd'].string[18:][1268:1274]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lrd_report.records['ab79a298-1f1a-44da-a174-6a52ae8abfcd'].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(monomer_strings['ab79a298-1f1a-44da-a174-6a52ae8abfcd'])['=']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
